{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson Regression - Newton Raphson\n",
    "#### by Andrew Rothman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will explore Poisson Regression where we will: <br>\n",
    "* Specify the statistical model and it's functional form\n",
    "* Using the Iris dataset as a motivating example, we will recover estimates of the parameters of the model we specified using the iterative numerical algorithm Newton Raphson."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Model Specification\n",
    "### Variables & Dimensions\n",
    "Let us begin by specifying our variable relations and matrix dimensions:\n",
    "\n",
    "$\\begin{align}\n",
    "Y\n",
    "\\end{align}$ ~ n iid Poisson RVs\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{Y} = A &= \\sigma(Z) = e^{Z} \\\\\n",
    "Z = X \\hat{\\beta} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$\\begin{aligned}\n",
    "n=\n",
    "\\end{aligned}$ number of observations\n",
    "\n",
    "$\\begin{aligned}\n",
    "p=\n",
    "\\end{aligned}$ number of parameters\n",
    "\n",
    "Note, that in this formulation we are imbedding the intercept term into the Design and Parameter matrices\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "Y, A, Z &: n\\times 1 \\\\\n",
    "X &: n\\times (p+1) \\\\\n",
    "\\hat{\\beta} &: (p+1)\\times 1 \\\\\n",
    "\\stackrel{\\rightarrow}{1} &: n\\times 1 \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function (Negative Log Likelihood)\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{L}(A|Y) &= \\prod_{i=1}^n \\frac{A^{Y}e^{-A}}{Y!}    \\\\\n",
    "-\\ln (\\mathcal{L}(A|Y)) = J &= \\sum_{i=1}^n -Y\\ln(A) + A + \\ln(Y!) \\\\\n",
    "J &= \\sum_{i=1}^n -YX\\hat{\\beta} + A + \\ln(Y!) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "in vectorized form, this reduces to:\n",
    "$$\n",
    "\\begin{align}\n",
    "J &= -Y^{T}X\\hat{\\beta} + (A+\\ln(Y!))^{T}\\stackrel{\\rightarrow}{1}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that:\n",
    "$$\n",
    "\\begin{align}\n",
    "J &= -Y^{T}X\\hat{\\beta} + (e^{X\\hat{\\beta}} + \\ln(Y!))^{T}\\stackrel{\\rightarrow}{1} \\\\\n",
    "\\frac{\\partial J}{\\partial \\hat{\\beta}} &= -Y^{T}X + (e^{X\\hat{\\beta}})^{T}X   \\\\\n",
    "\\frac{\\partial J}{\\partial \\hat{\\beta}} &= -Y^{T}X + A^{T}X   \\\\\n",
    "\\frac{\\partial J}{\\partial \\hat{\\beta}} &= X^{T}(A-Y)   \\\\\n",
    "\\frac{\\partial^{2} J}{\\partial^{2} \\hat{\\beta}} &= (e^{X\\hat{\\beta}})^{T}\\stackrel{\\rightarrow}{1}*X^{T}X   \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "### Newton Raphson Algorithm\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{\\beta}_{i+1} = \\hat{\\beta}_i - (\\frac{\\partial^{2} J}{\\partial^{2} \\hat{\\beta}_i})^{-1}\\frac{\\partial J}{\\partial \\hat{\\beta}_i}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Motivating Example with the \"Iris\" Dataset\n",
    "We will show the above closed form solution in action with a motivating example. We will use the Iris Dataset to do so by:\n",
    "* Using \"Sepal Length\" as our outcome of interest, with all remaining variables as covariates in the regression model\n",
    " * The variable \"Sepal Length\" has been reparameterized to a [0,1] variable with \n",
    "   * \"Sepal Length\" < 5.1 set to \"0\"\n",
    "   * 5.1 <= \"Sepal Length\" < 5.8 set to \"1\"\n",
    "   * 5.8 <= \"Sepal Length\" < 6.4 set to \"2\"\n",
    "   * \"Sepal Length\" >= 6.4 set to \"3\"\n",
    " * Note, the variable \"Species\" is reparameterized as \"one-hot\" coding, with the category \"virginica\" set as the reference category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "## import libraries ##\n",
    "######################\n",
    "from scipy.misc import factorial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import statsmodels.formula.api as sm\n",
    "from statsmodels.genmod.families import Poisson\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S_Length</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>S_Width</th>\n",
       "      <th>P_Length</th>\n",
       "      <th>P_Width</th>\n",
       "      <th>Species_setosa</th>\n",
       "      <th>Species_versicolor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.00000</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.58000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.11289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "      <td>0.472984</td>\n",
       "      <td>0.472984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        S_Length  Intercept     S_Width    P_Length     P_Width  \\\n",
       "count  150.00000      150.0  150.000000  150.000000  150.000000   \n",
       "mean     1.58000        1.0    3.054000    3.758667    1.198667   \n",
       "std      1.11289        0.0    0.433594    1.764420    0.763161   \n",
       "min      0.00000        1.0    2.000000    1.000000    0.100000   \n",
       "25%      1.00000        1.0    2.800000    1.600000    0.300000   \n",
       "50%      2.00000        1.0    3.000000    4.350000    1.300000   \n",
       "75%      3.00000        1.0    3.300000    5.100000    1.800000   \n",
       "max      3.00000        1.0    4.400000    6.900000    2.500000   \n",
       "\n",
       "       Species_setosa  Species_versicolor  \n",
       "count      150.000000          150.000000  \n",
       "mean         0.333333            0.333333  \n",
       "std          0.472984            0.472984  \n",
       "min          0.000000            0.000000  \n",
       "25%          0.000000            0.000000  \n",
       "50%          0.000000            0.000000  \n",
       "75%          1.000000            1.000000  \n",
       "max          1.000000            1.000000  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################\n",
    "## import and clean iris dataset ##\n",
    "###################################\n",
    "iris = datasets.load_iris()\n",
    "LR_df = pd.DataFrame()\n",
    "LR_df['S_Length'] = iris['data'][:,0]\n",
    "LR_df['Intercept']=np.full(iris['data'].shape[0], 1)\n",
    "LR_df['S_Width'] = iris['data'][:,1]\n",
    "LR_df['P_Length'] = iris['data'][:,2]\n",
    "LR_df['P_Width'] = iris['data'][:,3]\n",
    "LR_df['Species'] = iris['target']\n",
    "LR_df['Species'] = LR_df['Species'].apply(str)\n",
    "LR_df.loc[LR_df['Species']==str(0), \"Species\"] = str(iris['target_names'][0])\n",
    "LR_df.loc[LR_df['Species']==str(1), \"Species\"] = str(iris['target_names'][1])\n",
    "LR_df.loc[LR_df['Species']==str(2), \"Species\"] = str(iris['target_names'][2])\n",
    "LR_df['Species_setosa']=0\n",
    "LR_df.loc[LR_df['Species']=='setosa', 'Species_setosa']=1\n",
    "LR_df['Species_versicolor']=0\n",
    "LR_df.loc[LR_df['Species']=='versicolor', 'Species_versicolor']=1\n",
    "LR_df.loc[LR_df['S_Length']<5.1, 'S_Length'] = 0\n",
    "LR_df.loc[(LR_df['S_Length']>=5.1) & (LR_df['S_Length']<5.8), 'S_Length'] = 1\n",
    "LR_df.loc[(LR_df['S_Length']>=5.8) & (LR_df['S_Length']<6.4), 'S_Length'] = 2\n",
    "LR_df.loc[LR_df['S_Length']>=6.4, 'S_Length'] = 3\n",
    "LR_df = LR_df.drop('Species', axis=1)\n",
    "LR_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "## creat arrays for Gradient Descent ##\n",
    "#######################################\n",
    "Y = np.array(LR_df['S_Length']).reshape((len(LR_df['S_Length']), 1))\n",
    "X = np.array(LR_df[['Intercept', 'S_Width', 'P_Length', 'P_Width', 'Species_setosa', 'Species_versicolor']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Compute Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "## initialize parameter matrix ##\n",
    "#################################\n",
    "k = X.shape[1]\n",
    "np.random.seed(10815657)\n",
    "nudge=0.1\n",
    "Beta = np.random.uniform(low=-1*nudge, high=1*nudge, size=k).reshape(k, 1)\n",
    "Z = np.dot(X, Beta)\n",
    "A = np.exp(Z)\n",
    "ones_vector = np.full(Y.shape[0], 1).reshape(Y.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\Anaconda3\\envs\\py35\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: `factorial` is deprecated!\n",
      "Importing `factorial` from scipy.misc is deprecated in scipy 1.0.0. Use `scipy.special.factorial` instead.\n",
      "  \n",
      "C:\\Users\\Andrew\\Anaconda3\\envs\\py35\\lib\\site-packages\\ipykernel_launcher.py:17: DeprecationWarning: `factorial` is deprecated!\n",
      "Importing `factorial` from scipy.misc is deprecated in scipy 1.0.0. Use `scipy.special.factorial` instead.\n"
     ]
    }
   ],
   "source": [
    "############################\n",
    "## Newton Raphson Descent ##\n",
    "############################\n",
    "m = 5000\n",
    "J = pd.DataFrame()\n",
    "J['iterative_step'] = range(0,m+1)\n",
    "J['cost'] = np.full(m+1, None)\n",
    "J.loc[0, 'cost'] = np.asscalar(-np.dot(Y.T, np.dot(X, Beta)) + np.dot((A+factorial(Y)).T, ones_vector))                        \n",
    "\n",
    "for i in range(1, m+1):    \n",
    "    J_partial_Beta = np.dot(X.T, (A-Y))\n",
    "    J_2partial_Beta2 = np.dot(A.T, ones_vector)*np.dot(X.T, X)\n",
    "        \n",
    "    Beta = Beta - np.dot(inv(J_2partial_Beta2), J_partial_Beta)\n",
    "    Z = np.dot(X, Beta)\n",
    "    A = np.exp(Z)\n",
    "    J.loc[i, 'cost'] = np.asscalar(-np.dot(Y.T, np.dot(X, Beta)) + np.dot((A+factorial(Y)).T, ones_vector))   \n",
    "    del J_partial_Beta      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.38648466],\n",
       "       [ 0.56337825],\n",
       "       [ 0.3038413 ],\n",
       "       [-0.04229405],\n",
       "       [-0.77570476],\n",
       "       [ 0.10596279]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(J['iterative_step'], J['cost'])\n",
    "plt.title('Newton Rhapson') \n",
    "plt.xlabel('Iterative Step') \n",
    "plt.ylabel('Cost') \n",
    "Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.38648466]\n",
      " [ 0.56337825]\n",
      " [ 0.3038413 ]\n",
      " [-0.04229405]\n",
      " [-0.77570476]\n",
      " [ 0.10596279]]\n"
     ]
    }
   ],
   "source": [
    "print(Beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this solution to that provided by the Logistic model provided in the \"statsmodels\" package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept            -2.386490\n",
      "S_Width               0.563382\n",
      "P_Length              0.303841\n",
      "P_Width              -0.042296\n",
      "Species_setosa       -0.775741\n",
      "Species_versicolor    0.105962\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## built in package\n",
    "results = sm.glm(formula=\"S_Length ~ S_Width + P_Length + P_Width + Species_setosa + Species_versicolor\", data=LR_df, family=Poisson()).fit()\n",
    "print(results.params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
