{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Poisson Regression - Gradient Descent\n",
    "#### by Andrew Rothman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will explore Poisson Regression where we will: <br>\n",
    "* Specify the statistical model and it's functional form\n",
    "* Using the Iris dataset as a motivating example, we will recover estimates of the parameters of the model we specified using the iterative numerical algorithm Gradient Descent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Model Specification\n",
    "### Variables & Dimensions\n",
    "Let us begin by specifying our variable relations and matrix dimensions:\n",
    "\n",
    "$\\begin{align}\n",
    "Y\n",
    "\\end{align}$ ~ n iid Poisson RVs\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{Y} = A &= \\sigma(Z) = e^{Z} \\\\\n",
    "Z = X \\hat{\\beta} \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "$\\begin{aligned}\n",
    "n=\n",
    "\\end{aligned}$ number of observations\n",
    "\n",
    "$\\begin{aligned}\n",
    "p=\n",
    "\\end{aligned}$ number of parameters\n",
    "\n",
    "Note, that in this formulation we are imbedding the intercept term into the Design and Parameter matrices\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "Y, A, Z &: n\\times 1 \\\\\n",
    "X &: n\\times (p+1) \\\\\n",
    "\\hat{\\beta} &: (p+1)\\times 1 \\\\\n",
    "\\stackrel{\\rightarrow}{1} &: n\\times 1 \\\\\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost Function (Negative Log Likelihood)\n",
    "$$\n",
    "\\begin{align}\n",
    "\\mathcal{L}(A|Y) &= \\prod_{i=1}^n \\frac{A^{Y}e^{-A}}{Y!}    \\\\\n",
    "-\\ln (\\mathcal{L}(A|Y)) = J &= \\sum_{i=1}^n -Y\\ln(A) + A + \\ln(Y!) \\\\\n",
    "J &= \\sum_{i=1}^n -YX\\hat{\\beta} + A + \\ln(Y!) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "in vectorized form, this reduces to:\n",
    "$$\n",
    "\\begin{align}\n",
    "J &= -Y^{T}X\\hat{\\beta} + (A+\\ln(Y!))^{T}\\stackrel{\\rightarrow}{1}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that:\n",
    "$$\n",
    "\\begin{align}\n",
    "J &= -Y^{T}X\\hat{\\beta} + (e^{X\\hat{\\beta}} + \\ln(Y!))^{T}\\stackrel{\\rightarrow}{1} \\\\\n",
    "\\frac{\\partial J}{\\partial \\hat{\\beta}} &= -Y^{T}X + (e^{X\\hat{\\beta}})^{T}X   \\\\\n",
    "\\frac{\\partial J}{\\partial \\hat{\\beta}} &= -Y^{T}X + A^{T}X   \\\\\n",
    "\\frac{\\partial J}{\\partial \\hat{\\beta}} &= X^{T}(A-Y)   \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "### Gradient Descent Algorithm\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{\\beta}_{i+1} = \\hat{\\beta}_i - \\alpha*\\frac{\\partial J}{\\partial \\hat{\\beta}_i}\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Motivating Example with the \"Iris\" Dataset\n",
    "We will show the above closed form solution in action with a motivating example. We will use the Iris Dataset to do so by:\n",
    "* Using \"Sepal Length\" as our outcome of interest, with all remaining variables as covariates in the regression model\n",
    " * The variable \"Sepal Length\" has been reparameterized to a [0,1] variable with \n",
    "   * \"Sepal Length\" < 5.1 set to \"0\"\n",
    "   * 5.1 <= \"Sepal Length\" < 5.8 set to \"1\"\n",
    "   * 5.8 <= \"Sepal Length\" < 6.4 set to \"2\"\n",
    "   * \"Sepal Length\" >= 6.4 set to \"3\"\n",
    " * Note, the variable \"Species\" is reparameterized as \"one-hot\" coding, with the category \"virginica\" set as the reference category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "## import libraries ##\n",
    "######################\n",
    "from scipy.misc import factorial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import statsmodels.formula.api as sm\n",
    "from statsmodels.genmod.families import Poisson\n",
    "from numpy.linalg import inv\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>S_Length</th>\n",
       "      <th>Intercept</th>\n",
       "      <th>S_Width</th>\n",
       "      <th>P_Length</th>\n",
       "      <th>P_Width</th>\n",
       "      <th>Species_setosa</th>\n",
       "      <th>Species_versicolor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.00000</td>\n",
       "      <td>150.0</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.58000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.11289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "      <td>0.472984</td>\n",
       "      <td>0.472984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.00000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        S_Length  Intercept     S_Width    P_Length     P_Width  \\\n",
       "count  150.00000      150.0  150.000000  150.000000  150.000000   \n",
       "mean     1.58000        1.0    3.054000    3.758667    1.198667   \n",
       "std      1.11289        0.0    0.433594    1.764420    0.763161   \n",
       "min      0.00000        1.0    2.000000    1.000000    0.100000   \n",
       "25%      1.00000        1.0    2.800000    1.600000    0.300000   \n",
       "50%      2.00000        1.0    3.000000    4.350000    1.300000   \n",
       "75%      3.00000        1.0    3.300000    5.100000    1.800000   \n",
       "max      3.00000        1.0    4.400000    6.900000    2.500000   \n",
       "\n",
       "       Species_setosa  Species_versicolor  \n",
       "count      150.000000          150.000000  \n",
       "mean         0.333333            0.333333  \n",
       "std          0.472984            0.472984  \n",
       "min          0.000000            0.000000  \n",
       "25%          0.000000            0.000000  \n",
       "50%          0.000000            0.000000  \n",
       "75%          1.000000            1.000000  \n",
       "max          1.000000            1.000000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###################################\n",
    "## import and clean iris dataset ##\n",
    "###################################\n",
    "iris = datasets.load_iris()\n",
    "LR_df = pd.DataFrame()\n",
    "LR_df['S_Length'] = iris['data'][:,0]\n",
    "LR_df['Intercept']=np.full(iris['data'].shape[0], 1)\n",
    "LR_df['S_Width'] = iris['data'][:,1]\n",
    "LR_df['P_Length'] = iris['data'][:,2]\n",
    "LR_df['P_Width'] = iris['data'][:,3]\n",
    "LR_df['Species'] = iris['target']\n",
    "LR_df['Species'] = LR_df['Species'].apply(str)\n",
    "LR_df.loc[LR_df['Species']==str(0), \"Species\"] = str(iris['target_names'][0])\n",
    "LR_df.loc[LR_df['Species']==str(1), \"Species\"] = str(iris['target_names'][1])\n",
    "LR_df.loc[LR_df['Species']==str(2), \"Species\"] = str(iris['target_names'][2])\n",
    "LR_df['Species_setosa']=0\n",
    "LR_df.loc[LR_df['Species']=='setosa', 'Species_setosa']=1\n",
    "LR_df['Species_versicolor']=0\n",
    "LR_df.loc[LR_df['Species']=='versicolor', 'Species_versicolor']=1\n",
    "LR_df.loc[LR_df['S_Length']<5.1, 'S_Length'] = 0\n",
    "LR_df.loc[(LR_df['S_Length']>=5.1) & (LR_df['S_Length']<5.8), 'S_Length'] = 1\n",
    "LR_df.loc[(LR_df['S_Length']>=5.8) & (LR_df['S_Length']<6.4), 'S_Length'] = 2\n",
    "LR_df.loc[LR_df['S_Length']>=6.4, 'S_Length'] = 3\n",
    "LR_df = LR_df.drop('Species', axis=1)\n",
    "LR_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################\n",
    "## creat arrays for Gradient Descent ##\n",
    "#######################################\n",
    "Y = np.array(LR_df['S_Length']).reshape((len(LR_df['S_Length']), 1))\n",
    "X = np.array(LR_df[['Intercept', 'S_Width', 'P_Length', 'P_Width', 'Species_setosa', 'Species_versicolor']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) Compute Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################################\n",
    "## initialize parameter matrix ##\n",
    "#################################\n",
    "k = X.shape[1]\n",
    "np.random.seed(10815657)\n",
    "nudge=0.1\n",
    "Beta = np.random.uniform(low=-1*nudge, high=1*nudge, size=k).reshape(k, 1)\n",
    "Z = np.dot(X, Beta)\n",
    "A = np.exp(Z)\n",
    "ones_vector = np.full(Y.shape[0], 1).reshape(Y.shape[0], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Andrew\\Anaconda3\\envs\\py35\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: `factorial` is deprecated!\n",
      "Importing `factorial` from scipy.misc is deprecated in scipy 1.0.0. Use `scipy.special.factorial` instead.\n",
      "  if __name__ == '__main__':\n",
      "C:\\Users\\Andrew\\Anaconda3\\envs\\py35\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: `factorial` is deprecated!\n",
      "Importing `factorial` from scipy.misc is deprecated in scipy 1.0.0. Use `scipy.special.factorial` instead.\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "## Gradient Descent ##\n",
    "######################\n",
    "m = 60000\n",
    "alpha = 0.0002\n",
    "J = pd.DataFrame()\n",
    "J['iterative_step'] = range(0,m+1)\n",
    "J['cost'] = np.full(m+1, None)\n",
    "J.loc[0, 'cost'] = np.asscalar(-np.dot(Y.T, np.dot(X, Beta)) + np.dot((A+factorial(Y)).T, ones_vector))                        \n",
    "\n",
    "for i in range(1, m+1):    \n",
    "    J_partial_Beta = np.dot(X.T, (A-Y))\n",
    "    Beta = Beta - (alpha*J_partial_Beta)\n",
    "    Z = np.dot(X, Beta)\n",
    "    A = np.exp(Z)\n",
    "    J.loc[i, 'cost'] = np.asscalar(-np.dot(Y.T, np.dot(X, Beta)) + np.dot((A+factorial(Y)).T, ones_vector))   \n",
    "    del J_partial_Beta    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-2.38645103],\n",
       "       [ 0.56338587],\n",
       "       [ 0.30383546],\n",
       "       [-0.04230528],\n",
       "       [-0.77578323],\n",
       "       [ 0.10594811]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(J['iterative_step'], J['cost'])\n",
    "plt.title('Gradient Descent') \n",
    "plt.xlabel('Iterative Step') \n",
    "plt.ylabel('Cost') \n",
    "Beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.38645103]\n",
      " [ 0.56338587]\n",
      " [ 0.30383546]\n",
      " [-0.04230528]\n",
      " [-0.77578323]\n",
      " [ 0.10594811]]\n"
     ]
    }
   ],
   "source": [
    "print(Beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare this solution to that provided by the Logistic model provided in the \"statsmodels\" package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept            -2.386490\n",
      "S_Width               0.563382\n",
      "P_Length              0.303841\n",
      "P_Width              -0.042296\n",
      "Species_setosa       -0.775741\n",
      "Species_versicolor    0.105962\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "## built in package\n",
    "results = sm.glm(formula=\"S_Length ~ S_Width + P_Length + P_Width + Species_setosa + Species_versicolor\", data=LR_df, family=Poisson()).fit()\n",
    "print(results.params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
